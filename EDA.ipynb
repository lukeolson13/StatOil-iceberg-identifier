{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/luke/anaconda2/envs/py3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pickle\n",
    "import tensorflow\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Convolution2D, MaxPooling2D\n",
    "from keras.layers.pooling import GlobalMaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_scale_factors(images, angles, df, method):\n",
    "    b1_mean = images[:,:,:,0].mean()\n",
    "    b2_mean = images[:,:,:,1].mean()\n",
    "    ang_mean = np.nanmean(angles)\n",
    "\n",
    "    b1_std = images[:,:,:,0].std()\n",
    "    b2_std = images[:,:,:,1].std()\n",
    "    ang_std = np.nanstd(angles)\n",
    "    \n",
    "    scale_dict = {'b1_mean': b1_mean, 'b2_mean': b2_mean, 'ang_mean': ang_mean,\n",
    "                  'b1_std': b1_std, 'b2_std': b2_std, 'ang_std': ang_std}\n",
    "    if method != None:\n",
    "        b3_mean = images[:,:,:,2].mean()\n",
    "        b3_std = images[:,:,:,2].std()\n",
    "        scale_dict.update({'b3_mean': b3_mean, 'b3_std': b3_std})\n",
    "\n",
    "    pickle_out = open(\"dump/scale_dict.pickle\",\"wb\")\n",
    "    pickle.dump(scale_dict, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_both(images, angles, df, method):\n",
    "    pickle_in = open(\"dump/scale_dict.pickle\",\"rb\")\n",
    "    sd = pickle.load(pickle_in)\n",
    "    \n",
    "    images[:,:,:,0] = (images[:,:,:,0] - sd['b1_mean']) / sd['b1_std']\n",
    "    images[:,:,:,1] = (images[:,:,:,1] - sd['b2_mean']) / sd['b2_std']\n",
    "    if method != None:\n",
    "        images[:,:,:,2] = (images[:,:,:,2] - sd['b3_mean']) / sd['b3_std']\n",
    "    angles = (angles - sd['ang_mean']) / sd['ang_std']\n",
    "  \n",
    "    return images, angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB(images, method):\n",
    "    if method == 'ratio':\n",
    "        b3 = (images[:,:,:,0] / images[:,:,:,1]).reshape(-1, 75, 75, 1)\n",
    "        images = np.insert(images, [2], b3, axis=3)\n",
    "    elif method == 'mean':\n",
    "        b3 = ((images[:,:,:,0] + images[:,:,:,1]) / 2).reshape(-1, 75, 75, 1)\n",
    "        images = np.insert(images, [2], b3, axis=3)\n",
    "    else:\n",
    "        raise Exception(\"Must be method type of 'ratio' or 'mean'\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(df):\n",
    "    images = df.apply(lambda c_row: [np.stack([c_row['band_1'],c_row['band_2']], -1).reshape((75,75,2))],1)\n",
    "    images = np.stack(images).squeeze()\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y(path, scale=False, create_RGB=None, rs=1):\n",
    "    '''\n",
    "    Input: \n",
    "        path - path to data\n",
    "        split_bands - whether or not to split the band data (pixels) into their own columns\n",
    "        test_size - size of test data to break off of training data\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    '''\n",
    "    np.random.seed(rs)\n",
    "    kind = 'train' if len(path) == 10 else 'test'\n",
    "    \n",
    "    try:  # attempt to load previously created arrays\n",
    "        images = np.load('dump/{}_images_{}{}.dat'.format(kind, 'scaled' if scale else 'non-scaled',\n",
    "                                             '_{}'.format(create_RGB) if create_RGB != None else ''))\n",
    "        angles = np.load('dump/{}_angles_{}{}.dat'.format(kind, 'scaled' if scale else 'non-scaled',\n",
    "                                             '_{}'.format(create_RGB) if create_RGB != None else ''))\n",
    "        if kind == 'train':\n",
    "            y = np.load('dump/{}_y_{}{}.dat'.format(kind, 'scaled' if scale else 'non-scaled',\n",
    "                                             '_{}'.format(create_RGB) if create_RGB != None else ''))\n",
    "        else:\n",
    "            ids = np.load('dump/ids.dat')\n",
    "    except:  # if not array is available\n",
    "        print('Creating new data arrays...')\n",
    "        df = pd.read_json(path)\n",
    "        df = df.replace('na',np.NaN)\n",
    "        \n",
    "        images = get_images(df)\n",
    "        angles = df.inc_angle.values\n",
    "        \n",
    "        if create_RGB != None:\n",
    "            images = RGB(images, create_RGB)\n",
    "        \n",
    "        if scale:\n",
    "            if kind == 'train':\n",
    "                pickle_scale_factors(images, angles, df, create_RGB)\n",
    "            images, angles = scale_both(images, angles, df, create_RGB)\n",
    "            \n",
    "        images.dump('dump/{}_images_{}{}.dat'.format(kind, 'scaled' if scale else 'non-scaled',\n",
    "                                             '_{}'.format(create_RGB) if create_RGB != None else ''))\n",
    "        angles.dump('dump/{}_angles_{}{}.dat'.format(kind, 'scaled' if scale else 'non-scaled',\n",
    "                                             '_{}'.format(create_RGB) if create_RGB != None else ''))\n",
    "        if kind == 'train':\n",
    "            y = to_categorical(df.is_iceberg, num_classes=2)\n",
    "            y.dump('dump/{}_y_{}{}.dat'.format(kind, 'scaled' if scale else 'non-scaled',\n",
    "                                             '_{}'.format(create_RGB) if create_RGB != None else ''))\n",
    "        else:\n",
    "            ids = df.id.values\n",
    "            ids.dump('dump/ids.dat')\n",
    "    if kind == 'train':\n",
    "        return images, angles, y\n",
    "    else:\n",
    "        return images, angles, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "images, angles, y = X_y(\n",
    "    'train.json', \n",
    "    scale=True, \n",
    "    create_RGB=None\n",
    ")\n",
    "\n",
    "y = np.array([[int(x) for x in row] for row in y])\n",
    "\n",
    "images_train, images_val, angles_train, angles_val, y_train, y_val = train_test_split(\n",
    "    images, \n",
    "    angles, \n",
    "    y, \n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subset\n",
    "mask = np.random.randint(0, len(images), size=200)\n",
    "images_sub = images[mask]\n",
    "anlges_sub = angles[mask]\n",
    "y_sub = y[mask]\n",
    "\n",
    "images_sub_train, images_sub_val, angles_sub_train, angles_sub_val, y_sub_train, y_sub_val = train_test_split(\n",
    "    images_sub, \n",
    "    anlges_sub, \n",
    "    y_sub, \n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1283, 75, 75, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_3D(band, target_name):\n",
    "    data = [go.Surface(z=band)]\n",
    "    layout = go.Layout(title=target_name, autosize=False, width=700, height=700, \n",
    "                       margin=dict(l=65, r=50, b=65, t=90))\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3D plot of ship\n",
    "image_num = 9\n",
    "image_3D(images_train[image_num,:,:,0], 'iceberg' if y[image_num][1] == 1 else 'ship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_num = 6\n",
    "image_3D(images_train[image_num,:,:,0], 'iceberg' if y[image_num][1] == 1 else 'ship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_images, test_angles, ids = X_y(\n",
    "    'test.json', \n",
    "    scale=True, \n",
    "    create_RGB=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(shape, window_size=(3,3), stride=(1, 1), pooling_size=(2,2), activation_f='softmax',\n",
    "          op_f='adam', loss_f='binary_crossentropy', pad='same', dropout=0.5):\n",
    "    cnn = Sequential()\n",
    "    cnn.add(BatchNormalization(input_shape = shape))\n",
    "    for i in range(5):\n",
    "        cnn.add(Conv2D(filters=12**i, kernel_size=window_size, strides=stride, padding=pad))\n",
    "        cnn.add(MaxPooling2D(pooling_size))\n",
    "    cnn.add(GlobalMaxPooling2D())\n",
    "    cnn.add(Dropout(dropout))\n",
    "    cnn.add(Dense(8))\n",
    "    cnn.add(Dense(2, activation = activation_f))\n",
    "    cnn.compile(optimizer = op_f, loss = loss_f, metrics = ['accuracy'])\n",
    "    # cnn.summary()\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_cnn():\n",
    "    cnn = build_model(\n",
    "        shape=images_train.shape[1:], \n",
    "        window_size=(3,3), \n",
    "        stride=(1, 1), \n",
    "        pooling_size=(2,2), \n",
    "        activation_f='softmax',\n",
    "        op_f='adam', \n",
    "        loss_f='binary_crossentropy', \n",
    "        pad='same', \n",
    "        dropout=0.2\n",
    "    )\n",
    "    cnn.fit(\n",
    "        images_train, \n",
    "        y_train, \n",
    "        batch_size=None, \n",
    "        shuffle=True, \n",
    "        validation_data=(images_val, y_val), \n",
    "        epochs=5\n",
    "    )\n",
    "    return cnn.evaluate(images_val, y_val, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1283 samples, validate on 321 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "eval_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7fefd9f93ae0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/luke/anaconda2/envs/py3/lib/python3.6/site...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/luke/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fefd9f93ae0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/luke/anaconda2/envs/py3/lib/python3.6/site...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/luke/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    276         if self.control_stream:\n    277             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    278 \n    279         def make_dispatcher(stream):\n    280             def dispatcher(msg):\n--> 281                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    282             return dispatcher\n    283 \n    284         for s in self.shell_streams:\n    285             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 16, 14, 48, 11, 965000, tzinfo=tzutc()), 'msg_id': '70DBC0345C7347388C61A765D6FCF66A', 'msg_type': 'execute_request', 'session': '18E416B3C31F4E63979946D86C31DF8A', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '70DBC0345C7347388C61A765D6FCF66A', 'msg_type': 'execute_request', 'parent_header': {}})\n    227             self.log.warn(\"Unknown message type: %r\", msg_type)\n    228         else:\n    229             self.log.debug(\"%s: %s\", msg_type, msg)\n    230             self.pre_handler_hook()\n    231             try:\n--> 232                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'18E416B3C31F4E63979946D86C31DF8A']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 16, 14, 48, 11, 965000, tzinfo=tzutc()), 'msg_id': '70DBC0345C7347388C61A765D6FCF66A', 'msg_type': 'execute_request', 'session': '18E416B3C31F4E63979946D86C31DF8A', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '70DBC0345C7347388C61A765D6FCF66A', 'msg_type': 'execute_request', 'parent_header': {}}\n    233             except Exception:\n    234                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    235             finally:\n    236                 self.post_handler_hook()\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'18E416B3C31F4E63979946D86C31DF8A'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 16, 14, 48, 11, 965000, tzinfo=tzutc()), 'msg_id': '70DBC0345C7347388C61A765D6FCF66A', 'msg_type': 'execute_request', 'session': '18E416B3C31F4E63979946D86C31DF8A', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '70DBC0345C7347388C61A765D6FCF66A', 'msg_type': 'execute_request', 'parent_header': {}})\n    392         if not silent:\n    393             self.execution_count += 1\n    394             self._publish_execute_input(code, parent, self.execution_count)\n    395 \n    396         reply_content = self.do_execute(code, silent, store_history,\n--> 397                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    398 \n    399         # Flush output before sending the reply.\n    400         sys.stdout.flush()\n    401         sys.stderr.flush()\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.If object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-14-ecb6c5785484>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fef89ec47b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fef76848b70, file \"<ipython-input-14-ecb6c5785484>\", line 20>\n        result = <ExecutionResult object at 7fef89ec47b8, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fef76848b70, file \"<ipython-input-14-ecb6c5785484>\", line 20>, result=<ExecutionResult object at 7fef89ec47b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fef76848b70, file \"<ipython-input-14-ecb6c5785484>\", line 20>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'Adadelta': <class 'keras.optimizers.Adadelta'>, 'Adagrad': <class 'keras.optimizers.Adagrad'>, 'Adam': <class 'keras.optimizers.Adam'>, 'BatchNormalization': <class 'keras.layers.normalization.BatchNormalization'>, 'Conv2D': <class 'keras.layers.convolutional.Conv2D'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'Flatten': <class 'keras.layers.core.Flatten'>, ...}\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'Adadelta': <class 'keras.optimizers.Adadelta'>, 'Adagrad': <class 'keras.optimizers.Adagrad'>, 'Adam': <class 'keras.optimizers.Adam'>, 'BatchNormalization': <class 'keras.layers.normalization.BatchNormalization'>, 'Conv2D': <class 'keras.layers.convolutional.Conv2D'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'Flatten': <class 'keras.layers.core.Flatten'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/luke/Dropbox/Galvanize/Kaggle/iceburgs_statoil/<ipython-input-14-ecb6c5785484> in <module>()\n     15          'epochs': [5, 10], 'validation_data': [(x_v, y_v[:,1])], 'dropout': [0.2, 0.5, 0.7],\n     16          'loss_f': ['sparse_categorical_crossentropy']}\n     17 model = KerasClassifier(build_fn=build_model)\n     18 \n     19 grid = GridSearchCV(model, param_grid=params, n_jobs=-1, scoring='accuracy')\n---> 20 grid.fit(x_t, y_t[:,1])\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ore='warn',\n       scoring='accuracy', verbose=0), X=array([[[[-0.58871043, -0.18895022],\n         [-...3634316],\n         [-0.65906261, -0.60435624]]]]), y=array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[[[-0.58871043, -0.18895022],\n         [-...3634316],\n         [-0.65906261, -0.60435624]]]])\n        y = array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0])\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Jan 16 07:48:12 2018\nPID: 16763           Python 3.6.4: /home/luke/anaconda2/envs/py3/bin/python\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[[-0.58871043, -0.18895022],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), {'score': make_scorer(accuracy_score)}, array([ 54,  55,  56,  57,  58,  59,  60,  61,  ..., 152, 153, 154, 155, 156, 157,\n       158, 159]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53]), 0, {'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (3, 3), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (memmap([[[[-0.03378447,  0.19361609],\n          ...888896],\n          [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,... 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), ...}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[[-0.58871043, -0.18895022],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), {'score': make_scorer(accuracy_score)}, array([ 54,  55,  56,  57,  58,  59,  60,  61,  ..., 152, 153, 154, 155, 156, 157,\n       158, 159]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53]), 0, {'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (3, 3), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (memmap([[[[-0.03378447,  0.19361609],\n          ...888896],\n          [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,... 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), ...})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=memmap([[[[-0.58871043, -0.18895022],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), y=array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), scorer={'score': make_scorer(accuracy_score)}, train=array([ 54,  55,  56,  57,  58,  59,  60,  61,  ..., 152, 153, 154, 155, 156, 157,\n       158, 159]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53]), verbose=0, parameters={'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (3, 3), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (memmap([[[[-0.03378447,  0.19361609],\n          ...888896],\n          [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,... 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), ...}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]])\n        y_train = array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0])\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), y=array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]), **kwargs={})\n    198             self.classes_ = np.unique(y)\n    199             y = np.searchsorted(self.classes_, y)\n    200         else:\n    201             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    202         self.n_classes_ = len(self.classes_)\n--> 203         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]])\n        y = array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0])\n        kwargs = {}\n    204 \n    205     def predict(self, x, **kwargs):\n    206         \"\"\"Returns the class predictions for the given test data.\n    207 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), y=array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]), **kwargs={})\n    131         elif (not isinstance(self.build_fn, types.FunctionType) and\n    132               not isinstance(self.build_fn, types.MethodType)):\n    133             self.model = self.build_fn(\n    134                 **self.filter_sk_params(self.build_fn.__call__))\n    135         else:\n--> 136             self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n        self.model = undefined\n        self.build_fn = <function build_model>\n        self.filter_sk_params = <bound method BaseWrapper.filter_sk_params of <keras.wrappers.scikit_learn.KerasClassifier object>>\n    137 \n    138         loss_name = self.model.loss\n    139         if hasattr(loss_name, '__name__'):\n    140             loss_name = loss_name.__name__\n\n...........................................................................\n/home/luke/Dropbox/Galvanize/Kaggle/iceburgs_statoil/<ipython-input-12-c7c540e3e6f1> in build_model(shape=(75, 75, 2), window_size=(3, 3), stride=(1, 1), pooling_size=(3, 3), activation_f='relu', op_f='adam', loss_f='sparse_categorical_crossentropy', pad='same', dropout=0.2)\n      2           op_f='adam', loss_f='binary_crossentropy', pad='same', dropout=0.5):\n      3     cnn = Sequential()\n      4     cnn.add(BatchNormalization(input_shape = shape))\n      5     for i in range(5):\n      6         cnn.add(Conv2D(filters=12**i, kernel_size=window_size, strides=stride, padding=pad))\n----> 7         cnn.add(MaxPooling2D(pooling_size))\n      8     cnn.add(GlobalMaxPooling2D())\n      9     cnn.add(Dropout(dropout))\n     10     cnn.add(Dense(8))\n     11     cnn.add(Dense(2, activation = activation_f))\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/models.py in add(self=<keras.models.Sequential object>, layer=<keras.layers.pooling.MaxPooling2D object>)\n    484                           input_masks=[None for _ in self.inputs],\n    485                           output_masks=[None],\n    486                           input_shapes=[x._keras_shape for x in self.inputs],\n    487                           output_shapes=[self.outputs[0]._keras_shape])\n    488         else:\n--> 489             output_tensor = layer(self.outputs[0])\n        output_tensor = undefined\n        layer = <keras.layers.pooling.MaxPooling2D object>\n        self.outputs = [<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>]\n    490             if isinstance(output_tensor, list):\n    491                 raise TypeError('All layers in a Sequential model '\n    492                                 'should have a single output tensor. '\n    493                                 'For multi-output layers, '\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/topology.py in __call__(self=<keras.layers.pooling.MaxPooling2D object>, inputs=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, **kwargs={})\n    598                         kwargs['mask'] = previous_mask\n    599             # Handle automatic shape inference (only useful for Theano).\n    600             input_shape = _collect_input_shape(inputs)\n    601 \n    602             # Actually call the layer, collecting output(s), mask(s), and shape(s).\n--> 603             output = self.call(inputs, **kwargs)\n        output = undefined\n        self.call = <bound method _Pooling2D.call of <keras.layers.pooling.MaxPooling2D object>>\n        inputs = <tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>\n        kwargs = {}\n    604             output_mask = self.compute_mask(inputs, previous_mask)\n    605 \n    606             # If the layer returns tensors from its inputs, unmodified,\n    607             # we copy them to avoid loss of tensor metadata.\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/layers/pooling.py in call(self=<keras.layers.pooling.MaxPooling2D object>, inputs=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>)\n    149     def call(self, inputs):\n    150         output = self._pooling_function(inputs=inputs,\n    151                                         pool_size=self.pool_size,\n    152                                         strides=self.strides,\n    153                                         padding=self.padding,\n--> 154                                         data_format=self.data_format)\n        self.data_format = 'channels_last'\n    155         return output\n    156 \n    157     def get_config(self):\n    158         config = {'pool_size': self.pool_size,\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/layers/pooling.py in _pooling_function(self=<keras.layers.pooling.MaxPooling2D object>, inputs=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, pool_size=(3, 3), strides=(3, 3), padding='valid', data_format='channels_last')\n    212 \n    213     def _pooling_function(self, inputs, pool_size, strides,\n    214                           padding, data_format):\n    215         output = K.pool2d(inputs, pool_size, strides,\n    216                           padding, data_format,\n--> 217                           pool_mode='max')\n    218         return output\n    219 \n    220 \n    221 class AveragePooling2D(_Pooling2D):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in pool2d(x=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, pool_size=(1, 3, 3, 1), strides=(1, 3, 3, 1), padding='VALID', data_format='channels_last', pool_mode='max')\n   3461         pool_size = (1, 1) + pool_size\n   3462 \n   3463     if pool_mode == 'max':\n   3464         x = tf.nn.max_pool(x, pool_size, strides,\n   3465                            padding=padding,\n-> 3466                            data_format=tf_data_format)\n        data_format = 'channels_last'\n        tf_data_format = 'NHWC'\n   3467     elif pool_mode == 'avg':\n   3468         x = tf.nn.avg_pool(x, pool_size, strides,\n   3469                            padding=padding,\n   3470                            data_format=tf_data_format)\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py in max_pool(value=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, ksize=(1, 3, 3, 1), strides=(1, 3, 3, 1), padding='VALID', data_format='NHWC', name='max_pooling2d_4/MaxPool/')\n   1953     return gen_nn_ops._max_pool(value,\n   1954                                 ksize=ksize,\n   1955                                 strides=strides,\n   1956                                 padding=padding,\n   1957                                 data_format=data_format,\n-> 1958                                 name=name)\n        name = 'max_pooling2d_4/MaxPool/'\n   1959 \n   1960 \n   1961 @ops.RegisterStatistics(\"Conv2D\", \"flops\")\n   1962 def _calc_conv_flops(graph, node):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py in _max_pool(input=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, ksize=[1, 3, 3, 1], strides=[1, 3, 3, 1], padding=b'VALID', data_format=b'NHWC', name='max_pooling2d_4/MaxPool/')\n   2801   data_format = _execute.make_str(data_format, \"data_format\")\n   2802   _ctx = _context.context()\n   2803   if _ctx.in_graph_mode():\n   2804     _, _, _op = _op_def_lib._apply_op_helper(\n   2805         \"MaxPool\", input=input, ksize=ksize, strides=strides, padding=padding,\n-> 2806         data_format=data_format, name=name)\n        data_format = b'NHWC'\n        name = 'max_pooling2d_4/MaxPool/'\n   2807     _result = _op.outputs[:]\n   2808     _inputs_flat = _op.inputs\n   2809     _attrs = (\"T\", _op.get_attr(\"T\"), \"ksize\", _op.get_attr(\"ksize\"),\n   2810               \"strides\", _op.get_attr(\"strides\"), \"padding\",\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self=<tensorflow.python.framework.op_def_library.OpDefLibrary object>, op_type_name='MaxPool', name='max_pooling2d_4/MaxPool/', **keywords={})\n    782                               if arg.is_ref]\n    783       with _MaybeColocateWith(must_colocate_inputs):\n    784         # Add Op to graph\n    785         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n    786                          input_types=input_types, attrs=attr_protos,\n--> 787                          op_def=op_def)\n        op_def = name: \"MaxPool\"\ninput_arg {\n  name: \"input\"\n  ty...    s: \"NCHW\"\n      s: \"NCHW_VECT_C\"\n    }\n  }\n}\n\n    788       return output_structure, op_def.is_stateful, op\n    789 \n    790 # pylint: enable=invalid-name\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in create_op(self=<tensorflow.python.framework.ops.Graph object>, op_type='MaxPool', inputs=[<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>], dtypes=[1], input_types=[tf.float32], name='max_pooling2d_4/MaxPool', attrs={'T': type: DT_FLOAT\n, 'data_format': s: \"NHWC\"\n, 'ksize': list {\n  i: 1\n  i: 3\n  i: 3\n  i: 1\n}\n, 'padding': s: \"VALID\"\n, 'strides': list {\n  i: 1\n  i: 3\n  i: 3\n  i: 1\n}\n}, op_def=name: \"MaxPool\"\ninput_arg {\n  name: \"input\"\n  ty...    s: \"NCHW\"\n      s: \"NCHW_VECT_C\"\n    }\n  }\n}\n, compute_shapes=True, compute_device=True)\n   2953         control_inputs=control_inputs,\n   2954         input_types=input_types,\n   2955         original_op=self._default_original_op,\n   2956         op_def=op_def)\n   2957     if compute_shapes:\n-> 2958       set_shapes_for_outputs(ret)\n        ret = <tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>\n   2959     self._add_op(ret)\n   2960     self._record_op_seen_by_control_dependencies(ret)\n   2961 \n   2962     if compute_device:\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in set_shapes_for_outputs(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>)\n   2204     try:\n   2205       shape_func = _default_shape_function_registry.lookup(op.type)\n   2206     except LookupError:\n   2207       shape_func = _call_cpp_shape_fn_and_require_op\n   2208 \n-> 2209   shapes = shape_func(op)\n        shapes = undefined\n        shape_func = <function _set_call_cpp_shape_fn.<locals>.call_with_requiring>\n        op = <tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>\n   2210   if shapes is None:\n   2211     raise RuntimeError(\n   2212         \"Shape function for op %s did not return any shapes\" % op)\n   2213   elif isinstance(shapes, dict):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in call_with_requiring(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>)\n   2154     return call_cpp_shape_fn(op, require_shape_fn=False)\n   2155 \n   2156   _call_cpp_shape_fn = call_without_requiring\n   2157 \n   2158   def call_with_requiring(op):\n-> 2159     return call_cpp_shape_fn(op, require_shape_fn=True)\n        op = <tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>\n   2160 \n   2161   _call_cpp_shape_fn_and_require_op = call_with_requiring\n   2162 \n   2163 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py in call_cpp_shape_fn(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>, require_shape_fn=True)\n    622   input_tensors_as_shapes_needed = []\n    623 \n    624   while True:\n    625     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n    626                                   input_tensors_as_shapes_needed,\n--> 627                                   require_shape_fn)\n        require_shape_fn = True\n    628     if not isinstance(res, dict):\n    629       # Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\n    630       return res\n    631 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py in _call_cpp_shape_fn_impl(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>, input_tensors_needed=[], input_tensors_as_shapes_needed=[], require_shape_fn=True)\n    686           input_tensors_as_shapes, status)\n    687   except errors.InvalidArgumentError as err:\n    688     if err.message.startswith(\"No shape inference function exists for op\"):\n    689       missing_shape_fn = True\n    690     else:\n--> 691       raise ValueError(err.message)\n        err.message = undefined\n    692 \n    693   if missing_shape_fn:\n    694     if require_shape_fn:\n    695       raise RuntimeError(\n\nValueError: Negative dimension size caused by subtracting 3 from 2 for 'max_pooling2d_4/MaxPool' (op: 'MaxPool') with input shapes: [?,2,2,1728].\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 686, in _call_cpp_shape_fn_impl\n    input_tensors_as_shapes, status)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 3 from 2 for 'max_pooling2d_4/MaxPool' (op: 'MaxPool') with input shapes: [?,2,2,1728].\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\", line 203, in fit\n    return super(KerasClassifier, self).fit(x, y, **kwargs)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\", line 136, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n  File \"<ipython-input-12-c7c540e3e6f1>\", line 7, in build_model\n    cnn.add(MaxPooling2D(pooling_size))\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/models.py\", line 489, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/layers/pooling.py\", line 154, in call\n    data_format=self.data_format)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/layers/pooling.py\", line 217, in _pooling_function\n    pool_mode='max')\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3466, in pool2d\n    data_format=tf_data_format)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1958, in max_pool\n    name=name)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2806, in _max_pool\n    data_format=data_format, name=name)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2958, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2209, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2159, in call_with_requiring\n    return call_cpp_shape_fn(op, require_shape_fn=True)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 627, in call_cpp_shape_fn\n    require_shape_fn)\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\", line 691, in _call_cpp_shape_fn_impl\n    raise ValueError(err.message)\nValueError: Negative dimension size caused by subtracting 3 from 2 for 'max_pooling2d_4/MaxPool' (op: 'MaxPool') with input shapes: [?,2,2,1728].\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Jan 16 07:48:12 2018\nPID: 16763           Python 3.6.4: /home/luke/anaconda2/envs/py3/bin/python\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[[-0.58871043, -0.18895022],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), {'score': make_scorer(accuracy_score)}, array([ 54,  55,  56,  57,  58,  59,  60,  61,  ..., 152, 153, 154, 155, 156, 157,\n       158, 159]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53]), 0, {'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (3, 3), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (memmap([[[[-0.03378447,  0.19361609],\n          ...888896],\n          [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,... 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), ...}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[[-0.58871043, -0.18895022],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), {'score': make_scorer(accuracy_score)}, array([ 54,  55,  56,  57,  58,  59,  60,  61,  ..., 152, 153, 154, 155, 156, 157,\n       158, 159]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53]), 0, {'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (3, 3), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (memmap([[[[-0.03378447,  0.19361609],\n          ...888896],\n          [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,... 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), ...})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=memmap([[[[-0.58871043, -0.18895022],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), y=array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), scorer={'score': make_scorer(accuracy_score)}, train=array([ 54,  55,  56,  57,  58,  59,  60,  61,  ..., 152, 153, 154, 155, 156, 157,\n       158, 159]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53]), verbose=0, parameters={'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (3, 3), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (memmap([[[[-0.03378447,  0.19361609],\n          ...888896],\n          [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,... 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), ...}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]])\n        y_train = array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0])\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), y=array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]), **kwargs={})\n    198             self.classes_ = np.unique(y)\n    199             y = np.searchsorted(self.classes_, y)\n    200         else:\n    201             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    202         self.n_classes_ = len(self.classes_)\n--> 203         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]])\n        y = array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0])\n        kwargs = {}\n    204 \n    205     def predict(self, x, **kwargs):\n    206         \"\"\"Returns the class predictions for the given test data.\n    207 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), y=array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]), **kwargs={})\n    131         elif (not isinstance(self.build_fn, types.FunctionType) and\n    132               not isinstance(self.build_fn, types.MethodType)):\n    133             self.model = self.build_fn(\n    134                 **self.filter_sk_params(self.build_fn.__call__))\n    135         else:\n--> 136             self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n        self.model = undefined\n        self.build_fn = <function build_model>\n        self.filter_sk_params = <bound method BaseWrapper.filter_sk_params of <keras.wrappers.scikit_learn.KerasClassifier object>>\n    137 \n    138         loss_name = self.model.loss\n    139         if hasattr(loss_name, '__name__'):\n    140             loss_name = loss_name.__name__\n\n...........................................................................\n/home/luke/Dropbox/Galvanize/Kaggle/iceburgs_statoil/<ipython-input-12-c7c540e3e6f1> in build_model(shape=(75, 75, 2), window_size=(3, 3), stride=(1, 1), pooling_size=(3, 3), activation_f='relu', op_f='adam', loss_f='sparse_categorical_crossentropy', pad='same', dropout=0.2)\n      2           op_f='adam', loss_f='binary_crossentropy', pad='same', dropout=0.5):\n      3     cnn = Sequential()\n      4     cnn.add(BatchNormalization(input_shape = shape))\n      5     for i in range(5):\n      6         cnn.add(Conv2D(filters=12**i, kernel_size=window_size, strides=stride, padding=pad))\n----> 7         cnn.add(MaxPooling2D(pooling_size))\n      8     cnn.add(GlobalMaxPooling2D())\n      9     cnn.add(Dropout(dropout))\n     10     cnn.add(Dense(8))\n     11     cnn.add(Dense(2, activation = activation_f))\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/models.py in add(self=<keras.models.Sequential object>, layer=<keras.layers.pooling.MaxPooling2D object>)\n    484                           input_masks=[None for _ in self.inputs],\n    485                           output_masks=[None],\n    486                           input_shapes=[x._keras_shape for x in self.inputs],\n    487                           output_shapes=[self.outputs[0]._keras_shape])\n    488         else:\n--> 489             output_tensor = layer(self.outputs[0])\n        output_tensor = undefined\n        layer = <keras.layers.pooling.MaxPooling2D object>\n        self.outputs = [<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>]\n    490             if isinstance(output_tensor, list):\n    491                 raise TypeError('All layers in a Sequential model '\n    492                                 'should have a single output tensor. '\n    493                                 'For multi-output layers, '\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/topology.py in __call__(self=<keras.layers.pooling.MaxPooling2D object>, inputs=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, **kwargs={})\n    598                         kwargs['mask'] = previous_mask\n    599             # Handle automatic shape inference (only useful for Theano).\n    600             input_shape = _collect_input_shape(inputs)\n    601 \n    602             # Actually call the layer, collecting output(s), mask(s), and shape(s).\n--> 603             output = self.call(inputs, **kwargs)\n        output = undefined\n        self.call = <bound method _Pooling2D.call of <keras.layers.pooling.MaxPooling2D object>>\n        inputs = <tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>\n        kwargs = {}\n    604             output_mask = self.compute_mask(inputs, previous_mask)\n    605 \n    606             # If the layer returns tensors from its inputs, unmodified,\n    607             # we copy them to avoid loss of tensor metadata.\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/layers/pooling.py in call(self=<keras.layers.pooling.MaxPooling2D object>, inputs=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>)\n    149     def call(self, inputs):\n    150         output = self._pooling_function(inputs=inputs,\n    151                                         pool_size=self.pool_size,\n    152                                         strides=self.strides,\n    153                                         padding=self.padding,\n--> 154                                         data_format=self.data_format)\n        self.data_format = 'channels_last'\n    155         return output\n    156 \n    157     def get_config(self):\n    158         config = {'pool_size': self.pool_size,\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/layers/pooling.py in _pooling_function(self=<keras.layers.pooling.MaxPooling2D object>, inputs=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, pool_size=(3, 3), strides=(3, 3), padding='valid', data_format='channels_last')\n    212 \n    213     def _pooling_function(self, inputs, pool_size, strides,\n    214                           padding, data_format):\n    215         output = K.pool2d(inputs, pool_size, strides,\n    216                           padding, data_format,\n--> 217                           pool_mode='max')\n    218         return output\n    219 \n    220 \n    221 class AveragePooling2D(_Pooling2D):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in pool2d(x=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, pool_size=(1, 3, 3, 1), strides=(1, 3, 3, 1), padding='VALID', data_format='channels_last', pool_mode='max')\n   3461         pool_size = (1, 1) + pool_size\n   3462 \n   3463     if pool_mode == 'max':\n   3464         x = tf.nn.max_pool(x, pool_size, strides,\n   3465                            padding=padding,\n-> 3466                            data_format=tf_data_format)\n        data_format = 'channels_last'\n        tf_data_format = 'NHWC'\n   3467     elif pool_mode == 'avg':\n   3468         x = tf.nn.avg_pool(x, pool_size, strides,\n   3469                            padding=padding,\n   3470                            data_format=tf_data_format)\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py in max_pool(value=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, ksize=(1, 3, 3, 1), strides=(1, 3, 3, 1), padding='VALID', data_format='NHWC', name='max_pooling2d_4/MaxPool/')\n   1953     return gen_nn_ops._max_pool(value,\n   1954                                 ksize=ksize,\n   1955                                 strides=strides,\n   1956                                 padding=padding,\n   1957                                 data_format=data_format,\n-> 1958                                 name=name)\n        name = 'max_pooling2d_4/MaxPool/'\n   1959 \n   1960 \n   1961 @ops.RegisterStatistics(\"Conv2D\", \"flops\")\n   1962 def _calc_conv_flops(graph, node):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py in _max_pool(input=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, ksize=[1, 3, 3, 1], strides=[1, 3, 3, 1], padding=b'VALID', data_format=b'NHWC', name='max_pooling2d_4/MaxPool/')\n   2801   data_format = _execute.make_str(data_format, \"data_format\")\n   2802   _ctx = _context.context()\n   2803   if _ctx.in_graph_mode():\n   2804     _, _, _op = _op_def_lib._apply_op_helper(\n   2805         \"MaxPool\", input=input, ksize=ksize, strides=strides, padding=padding,\n-> 2806         data_format=data_format, name=name)\n        data_format = b'NHWC'\n        name = 'max_pooling2d_4/MaxPool/'\n   2807     _result = _op.outputs[:]\n   2808     _inputs_flat = _op.inputs\n   2809     _attrs = (\"T\", _op.get_attr(\"T\"), \"ksize\", _op.get_attr(\"ksize\"),\n   2810               \"strides\", _op.get_attr(\"strides\"), \"padding\",\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self=<tensorflow.python.framework.op_def_library.OpDefLibrary object>, op_type_name='MaxPool', name='max_pooling2d_4/MaxPool/', **keywords={})\n    782                               if arg.is_ref]\n    783       with _MaybeColocateWith(must_colocate_inputs):\n    784         # Add Op to graph\n    785         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n    786                          input_types=input_types, attrs=attr_protos,\n--> 787                          op_def=op_def)\n        op_def = name: \"MaxPool\"\ninput_arg {\n  name: \"input\"\n  ty...    s: \"NCHW\"\n      s: \"NCHW_VECT_C\"\n    }\n  }\n}\n\n    788       return output_structure, op_def.is_stateful, op\n    789 \n    790 # pylint: enable=invalid-name\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in create_op(self=<tensorflow.python.framework.ops.Graph object>, op_type='MaxPool', inputs=[<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>], dtypes=[1], input_types=[tf.float32], name='max_pooling2d_4/MaxPool', attrs={'T': type: DT_FLOAT\n, 'data_format': s: \"NHWC\"\n, 'ksize': list {\n  i: 1\n  i: 3\n  i: 3\n  i: 1\n}\n, 'padding': s: \"VALID\"\n, 'strides': list {\n  i: 1\n  i: 3\n  i: 3\n  i: 1\n}\n}, op_def=name: \"MaxPool\"\ninput_arg {\n  name: \"input\"\n  ty...    s: \"NCHW\"\n      s: \"NCHW_VECT_C\"\n    }\n  }\n}\n, compute_shapes=True, compute_device=True)\n   2953         control_inputs=control_inputs,\n   2954         input_types=input_types,\n   2955         original_op=self._default_original_op,\n   2956         op_def=op_def)\n   2957     if compute_shapes:\n-> 2958       set_shapes_for_outputs(ret)\n        ret = <tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>\n   2959     self._add_op(ret)\n   2960     self._record_op_seen_by_control_dependencies(ret)\n   2961 \n   2962     if compute_device:\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in set_shapes_for_outputs(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>)\n   2204     try:\n   2205       shape_func = _default_shape_function_registry.lookup(op.type)\n   2206     except LookupError:\n   2207       shape_func = _call_cpp_shape_fn_and_require_op\n   2208 \n-> 2209   shapes = shape_func(op)\n        shapes = undefined\n        shape_func = <function _set_call_cpp_shape_fn.<locals>.call_with_requiring>\n        op = <tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>\n   2210   if shapes is None:\n   2211     raise RuntimeError(\n   2212         \"Shape function for op %s did not return any shapes\" % op)\n   2213   elif isinstance(shapes, dict):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in call_with_requiring(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>)\n   2154     return call_cpp_shape_fn(op, require_shape_fn=False)\n   2155 \n   2156   _call_cpp_shape_fn = call_without_requiring\n   2157 \n   2158   def call_with_requiring(op):\n-> 2159     return call_cpp_shape_fn(op, require_shape_fn=True)\n        op = <tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>\n   2160 \n   2161   _call_cpp_shape_fn_and_require_op = call_with_requiring\n   2162 \n   2163 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py in call_cpp_shape_fn(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>, require_shape_fn=True)\n    622   input_tensors_as_shapes_needed = []\n    623 \n    624   while True:\n    625     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n    626                                   input_tensors_as_shapes_needed,\n--> 627                                   require_shape_fn)\n        require_shape_fn = True\n    628     if not isinstance(res, dict):\n    629       # Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\n    630       return res\n    631 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py in _call_cpp_shape_fn_impl(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>, input_tensors_needed=[], input_tensors_as_shapes_needed=[], require_shape_fn=True)\n    686           input_tensors_as_shapes, status)\n    687   except errors.InvalidArgumentError as err:\n    688     if err.message.startswith(\"No shape inference function exists for op\"):\n    689       missing_shape_fn = True\n    690     else:\n--> 691       raise ValueError(err.message)\n        err.message = undefined\n    692 \n    693   if missing_shape_fn:\n    694     if require_shape_fn:\n    695       raise RuntimeError(\n\nValueError: Negative dimension size caused by subtracting 3 from 2 for 'max_pooling2d_4/MaxPool' (op: 'MaxPool') with input shapes: [?,2,2,1728].\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Jan 16 07:48:12 2018\nPID: 16763           Python 3.6.4: /home/luke/anaconda2/envs/py3/bin/python\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[[-0.58871043, -0.18895022],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), {'score': make_scorer(accuracy_score)}, array([ 54,  55,  56,  57,  58,  59,  60,  61,  ..., 152, 153, 154, 155, 156, 157,\n       158, 159]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53]), 0, {'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (3, 3), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (memmap([[[[-0.03378447,  0.19361609],\n          ...888896],\n          [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,... 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), ...}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[[-0.58871043, -0.18895022],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), {'score': make_scorer(accuracy_score)}, array([ 54,  55,  56,  57,  58,  59,  60,  61,  ..., 152, 153, 154, 155, 156, 157,\n       158, 159]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53]), 0, {'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (3, 3), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (memmap([[[[-0.03378447,  0.19361609],\n          ...888896],\n          [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,... 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), ...})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=memmap([[[[-0.58871043, -0.18895022],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), y=array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), scorer={'score': make_scorer(accuracy_score)}, train=array([ 54,  55,  56,  57,  58,  59,  60,  61,  ..., 152, 153, 154, 155, 156, 157,\n       158, 159]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53]), verbose=0, parameters={'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (3, 3), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (memmap([[[[-0.03378447,  0.19361609],\n          ...888896],\n          [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,... 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), ...}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]])\n        y_train = array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0])\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), y=array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]), **kwargs={})\n    198             self.classes_ = np.unique(y)\n    199             y = np.searchsorted(self.classes_, y)\n    200         else:\n    201             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    202         self.n_classes_ = len(self.classes_)\n--> 203         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]])\n        y = array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0])\n        kwargs = {}\n    204 \n    205     def predict(self, x, **kwargs):\n    206         \"\"\"Returns the class predictions for the given test data.\n    207 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), y=array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]), **kwargs={})\n    131         elif (not isinstance(self.build_fn, types.FunctionType) and\n    132               not isinstance(self.build_fn, types.MethodType)):\n    133             self.model = self.build_fn(\n    134                 **self.filter_sk_params(self.build_fn.__call__))\n    135         else:\n--> 136             self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n        self.model = undefined\n        self.build_fn = <function build_model>\n        self.filter_sk_params = <bound method BaseWrapper.filter_sk_params of <keras.wrappers.scikit_learn.KerasClassifier object>>\n    137 \n    138         loss_name = self.model.loss\n    139         if hasattr(loss_name, '__name__'):\n    140             loss_name = loss_name.__name__\n\n...........................................................................\n/home/luke/Dropbox/Galvanize/Kaggle/iceburgs_statoil/<ipython-input-12-c7c540e3e6f1> in build_model(shape=(75, 75, 2), window_size=(3, 3), stride=(1, 1), pooling_size=(3, 3), activation_f='relu', op_f='adam', loss_f='sparse_categorical_crossentropy', pad='same', dropout=0.2)\n      2           op_f='adam', loss_f='binary_crossentropy', pad='same', dropout=0.5):\n      3     cnn = Sequential()\n      4     cnn.add(BatchNormalization(input_shape = shape))\n      5     for i in range(5):\n      6         cnn.add(Conv2D(filters=12**i, kernel_size=window_size, strides=stride, padding=pad))\n----> 7         cnn.add(MaxPooling2D(pooling_size))\n      8     cnn.add(GlobalMaxPooling2D())\n      9     cnn.add(Dropout(dropout))\n     10     cnn.add(Dense(8))\n     11     cnn.add(Dense(2, activation = activation_f))\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/models.py in add(self=<keras.models.Sequential object>, layer=<keras.layers.pooling.MaxPooling2D object>)\n    484                           input_masks=[None for _ in self.inputs],\n    485                           output_masks=[None],\n    486                           input_shapes=[x._keras_shape for x in self.inputs],\n    487                           output_shapes=[self.outputs[0]._keras_shape])\n    488         else:\n--> 489             output_tensor = layer(self.outputs[0])\n        output_tensor = undefined\n        layer = <keras.layers.pooling.MaxPooling2D object>\n        self.outputs = [<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>]\n    490             if isinstance(output_tensor, list):\n    491                 raise TypeError('All layers in a Sequential model '\n    492                                 'should have a single output tensor. '\n    493                                 'For multi-output layers, '\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/topology.py in __call__(self=<keras.layers.pooling.MaxPooling2D object>, inputs=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, **kwargs={})\n    598                         kwargs['mask'] = previous_mask\n    599             # Handle automatic shape inference (only useful for Theano).\n    600             input_shape = _collect_input_shape(inputs)\n    601 \n    602             # Actually call the layer, collecting output(s), mask(s), and shape(s).\n--> 603             output = self.call(inputs, **kwargs)\n        output = undefined\n        self.call = <bound method _Pooling2D.call of <keras.layers.pooling.MaxPooling2D object>>\n        inputs = <tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>\n        kwargs = {}\n    604             output_mask = self.compute_mask(inputs, previous_mask)\n    605 \n    606             # If the layer returns tensors from its inputs, unmodified,\n    607             # we copy them to avoid loss of tensor metadata.\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/layers/pooling.py in call(self=<keras.layers.pooling.MaxPooling2D object>, inputs=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>)\n    149     def call(self, inputs):\n    150         output = self._pooling_function(inputs=inputs,\n    151                                         pool_size=self.pool_size,\n    152                                         strides=self.strides,\n    153                                         padding=self.padding,\n--> 154                                         data_format=self.data_format)\n        self.data_format = 'channels_last'\n    155         return output\n    156 \n    157     def get_config(self):\n    158         config = {'pool_size': self.pool_size,\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/layers/pooling.py in _pooling_function(self=<keras.layers.pooling.MaxPooling2D object>, inputs=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, pool_size=(3, 3), strides=(3, 3), padding='valid', data_format='channels_last')\n    212 \n    213     def _pooling_function(self, inputs, pool_size, strides,\n    214                           padding, data_format):\n    215         output = K.pool2d(inputs, pool_size, strides,\n    216                           padding, data_format,\n--> 217                           pool_mode='max')\n    218         return output\n    219 \n    220 \n    221 class AveragePooling2D(_Pooling2D):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in pool2d(x=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, pool_size=(1, 3, 3, 1), strides=(1, 3, 3, 1), padding='VALID', data_format='channels_last', pool_mode='max')\n   3461         pool_size = (1, 1) + pool_size\n   3462 \n   3463     if pool_mode == 'max':\n   3464         x = tf.nn.max_pool(x, pool_size, strides,\n   3465                            padding=padding,\n-> 3466                            data_format=tf_data_format)\n        data_format = 'channels_last'\n        tf_data_format = 'NHWC'\n   3467     elif pool_mode == 'avg':\n   3468         x = tf.nn.avg_pool(x, pool_size, strides,\n   3469                            padding=padding,\n   3470                            data_format=tf_data_format)\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py in max_pool(value=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, ksize=(1, 3, 3, 1), strides=(1, 3, 3, 1), padding='VALID', data_format='NHWC', name='max_pooling2d_4/MaxPool/')\n   1953     return gen_nn_ops._max_pool(value,\n   1954                                 ksize=ksize,\n   1955                                 strides=strides,\n   1956                                 padding=padding,\n   1957                                 data_format=data_format,\n-> 1958                                 name=name)\n        name = 'max_pooling2d_4/MaxPool/'\n   1959 \n   1960 \n   1961 @ops.RegisterStatistics(\"Conv2D\", \"flops\")\n   1962 def _calc_conv_flops(graph, node):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py in _max_pool(input=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, ksize=[1, 3, 3, 1], strides=[1, 3, 3, 1], padding=b'VALID', data_format=b'NHWC', name='max_pooling2d_4/MaxPool/')\n   2801   data_format = _execute.make_str(data_format, \"data_format\")\n   2802   _ctx = _context.context()\n   2803   if _ctx.in_graph_mode():\n   2804     _, _, _op = _op_def_lib._apply_op_helper(\n   2805         \"MaxPool\", input=input, ksize=ksize, strides=strides, padding=padding,\n-> 2806         data_format=data_format, name=name)\n        data_format = b'NHWC'\n        name = 'max_pooling2d_4/MaxPool/'\n   2807     _result = _op.outputs[:]\n   2808     _inputs_flat = _op.inputs\n   2809     _attrs = (\"T\", _op.get_attr(\"T\"), \"ksize\", _op.get_attr(\"ksize\"),\n   2810               \"strides\", _op.get_attr(\"strides\"), \"padding\",\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self=<tensorflow.python.framework.op_def_library.OpDefLibrary object>, op_type_name='MaxPool', name='max_pooling2d_4/MaxPool/', **keywords={})\n    782                               if arg.is_ref]\n    783       with _MaybeColocateWith(must_colocate_inputs):\n    784         # Add Op to graph\n    785         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n    786                          input_types=input_types, attrs=attr_protos,\n--> 787                          op_def=op_def)\n        op_def = name: \"MaxPool\"\ninput_arg {\n  name: \"input\"\n  ty...    s: \"NCHW\"\n      s: \"NCHW_VECT_C\"\n    }\n  }\n}\n\n    788       return output_structure, op_def.is_stateful, op\n    789 \n    790 # pylint: enable=invalid-name\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in create_op(self=<tensorflow.python.framework.ops.Graph object>, op_type='MaxPool', inputs=[<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>], dtypes=[1], input_types=[tf.float32], name='max_pooling2d_4/MaxPool', attrs={'T': type: DT_FLOAT\n, 'data_format': s: \"NHWC\"\n, 'ksize': list {\n  i: 1\n  i: 3\n  i: 3\n  i: 1\n}\n, 'padding': s: \"VALID\"\n, 'strides': list {\n  i: 1\n  i: 3\n  i: 3\n  i: 1\n}\n}, op_def=name: \"MaxPool\"\ninput_arg {\n  name: \"input\"\n  ty...    s: \"NCHW\"\n      s: \"NCHW_VECT_C\"\n    }\n  }\n}\n, compute_shapes=True, compute_device=True)\n   2953         control_inputs=control_inputs,\n   2954         input_types=input_types,\n   2955         original_op=self._default_original_op,\n   2956         op_def=op_def)\n   2957     if compute_shapes:\n-> 2958       set_shapes_for_outputs(ret)\n        ret = <tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>\n   2959     self._add_op(ret)\n   2960     self._record_op_seen_by_control_dependencies(ret)\n   2961 \n   2962     if compute_device:\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in set_shapes_for_outputs(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>)\n   2204     try:\n   2205       shape_func = _default_shape_function_registry.lookup(op.type)\n   2206     except LookupError:\n   2207       shape_func = _call_cpp_shape_fn_and_require_op\n   2208 \n-> 2209   shapes = shape_func(op)\n        shapes = undefined\n        shape_func = <function _set_call_cpp_shape_fn.<locals>.call_with_requiring>\n        op = <tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>\n   2210   if shapes is None:\n   2211     raise RuntimeError(\n   2212         \"Shape function for op %s did not return any shapes\" % op)\n   2213   elif isinstance(shapes, dict):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in call_with_requiring(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>)\n   2154     return call_cpp_shape_fn(op, require_shape_fn=False)\n   2155 \n   2156   _call_cpp_shape_fn = call_without_requiring\n   2157 \n   2158   def call_with_requiring(op):\n-> 2159     return call_cpp_shape_fn(op, require_shape_fn=True)\n        op = <tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>\n   2160 \n   2161   _call_cpp_shape_fn_and_require_op = call_with_requiring\n   2162 \n   2163 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py in call_cpp_shape_fn(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>, require_shape_fn=True)\n    622   input_tensors_as_shapes_needed = []\n    623 \n    624   while True:\n    625     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n    626                                   input_tensors_as_shapes_needed,\n--> 627                                   require_shape_fn)\n        require_shape_fn = True\n    628     if not isinstance(res, dict):\n    629       # Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\n    630       return res\n    631 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py in _call_cpp_shape_fn_impl(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>, input_tensors_needed=[], input_tensors_as_shapes_needed=[], require_shape_fn=True)\n    686           input_tensors_as_shapes, status)\n    687   except errors.InvalidArgumentError as err:\n    688     if err.message.startswith(\"No shape inference function exists for op\"):\n    689       missing_shape_fn = True\n    690     else:\n--> 691       raise ValueError(err.message)\n        err.message = undefined\n    692 \n    693   if missing_shape_fn:\n    694     if require_shape_fn:\n    695       raise RuntimeError(\n\nValueError: Negative dimension size caused by subtracting 3 from 2 for 'max_pooling2d_4/MaxPool' (op: 'MaxPool') with input shapes: [?,2,2,1728].\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ecb6c5785484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7fefd9f93ae0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/luke/anaconda2/envs/py3/lib/python3.6/site...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/luke/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fefd9f93ae0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/luke/anaconda2/envs/py3/lib/python3.6/site...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/luke/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    276         if self.control_stream:\n    277             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    278 \n    279         def make_dispatcher(stream):\n    280             def dispatcher(msg):\n--> 281                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    282             return dispatcher\n    283 \n    284         for s in self.shell_streams:\n    285             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 16, 14, 48, 11, 965000, tzinfo=tzutc()), 'msg_id': '70DBC0345C7347388C61A765D6FCF66A', 'msg_type': 'execute_request', 'session': '18E416B3C31F4E63979946D86C31DF8A', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '70DBC0345C7347388C61A765D6FCF66A', 'msg_type': 'execute_request', 'parent_header': {}})\n    227             self.log.warn(\"Unknown message type: %r\", msg_type)\n    228         else:\n    229             self.log.debug(\"%s: %s\", msg_type, msg)\n    230             self.pre_handler_hook()\n    231             try:\n--> 232                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'18E416B3C31F4E63979946D86C31DF8A']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 16, 14, 48, 11, 965000, tzinfo=tzutc()), 'msg_id': '70DBC0345C7347388C61A765D6FCF66A', 'msg_type': 'execute_request', 'session': '18E416B3C31F4E63979946D86C31DF8A', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '70DBC0345C7347388C61A765D6FCF66A', 'msg_type': 'execute_request', 'parent_header': {}}\n    233             except Exception:\n    234                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    235             finally:\n    236                 self.post_handler_hook()\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'18E416B3C31F4E63979946D86C31DF8A'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 16, 14, 48, 11, 965000, tzinfo=tzutc()), 'msg_id': '70DBC0345C7347388C61A765D6FCF66A', 'msg_type': 'execute_request', 'session': '18E416B3C31F4E63979946D86C31DF8A', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '70DBC0345C7347388C61A765D6FCF66A', 'msg_type': 'execute_request', 'parent_header': {}})\n    392         if not silent:\n    393             self.execution_count += 1\n    394             self._publish_execute_input(code, parent, self.execution_count)\n    395 \n    396         reply_content = self.do_execute(code, silent, store_history,\n--> 397                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    398 \n    399         # Flush output before sending the reply.\n    400         sys.stdout.flush()\n    401         sys.stderr.flush()\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"use_subset = 1\\nif use_subset:\\n    x_t = images_s...s=-1, scoring='accuracy')\\ngrid.fit(x_t, y_t[:,1])\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.If object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-14-ecb6c5785484>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fef89ec47b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fef76848b70, file \"<ipython-input-14-ecb6c5785484>\", line 20>\n        result = <ExecutionResult object at 7fef89ec47b8, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fef76848b70, file \"<ipython-input-14-ecb6c5785484>\", line 20>, result=<ExecutionResult object at 7fef89ec47b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fef76848b70, file \"<ipython-input-14-ecb6c5785484>\", line 20>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'Adadelta': <class 'keras.optimizers.Adadelta'>, 'Adagrad': <class 'keras.optimizers.Adagrad'>, 'Adam': <class 'keras.optimizers.Adam'>, 'BatchNormalization': <class 'keras.layers.normalization.BatchNormalization'>, 'Conv2D': <class 'keras.layers.convolutional.Conv2D'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'Flatten': <class 'keras.layers.core.Flatten'>, ...}\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'Adadelta': <class 'keras.optimizers.Adadelta'>, 'Adagrad': <class 'keras.optimizers.Adagrad'>, 'Adam': <class 'keras.optimizers.Adam'>, 'BatchNormalization': <class 'keras.layers.normalization.BatchNormalization'>, 'Conv2D': <class 'keras.layers.convolutional.Conv2D'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'Flatten': <class 'keras.layers.core.Flatten'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/luke/Dropbox/Galvanize/Kaggle/iceburgs_statoil/<ipython-input-14-ecb6c5785484> in <module>()\n     15          'epochs': [5, 10], 'validation_data': [(x_v, y_v[:,1])], 'dropout': [0.2, 0.5, 0.7],\n     16          'loss_f': ['sparse_categorical_crossentropy']}\n     17 model = KerasClassifier(build_fn=build_model)\n     18 \n     19 grid = GridSearchCV(model, param_grid=params, n_jobs=-1, scoring='accuracy')\n---> 20 grid.fit(x_t, y_t[:,1])\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ore='warn',\n       scoring='accuracy', verbose=0), X=array([[[[-0.58871043, -0.18895022],\n         [-...3634316],\n         [-0.65906261, -0.60435624]]]]), y=array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[[[-0.58871043, -0.18895022],\n         [-...3634316],\n         [-0.65906261, -0.60435624]]]])\n        y = array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0])\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Jan 16 07:48:12 2018\nPID: 16763           Python 3.6.4: /home/luke/anaconda2/envs/py3/bin/python\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[[-0.58871043, -0.18895022],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), {'score': make_scorer(accuracy_score)}, array([ 54,  55,  56,  57,  58,  59,  60,  61,  ..., 152, 153, 154, 155, 156, 157,\n       158, 159]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53]), 0, {'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (3, 3), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (memmap([[[[-0.03378447,  0.19361609],\n          ...888896],\n          [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,... 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), ...}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[[-0.58871043, -0.18895022],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), {'score': make_scorer(accuracy_score)}, array([ 54,  55,  56,  57,  58,  59,  60,  61,  ..., 152, 153, 154, 155, 156, 157,\n       158, 159]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53]), 0, {'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (3, 3), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (memmap([[[[-0.03378447,  0.19361609],\n          ...888896],\n          [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,... 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), ...})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=memmap([[[[-0.58871043, -0.18895022],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), y=array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,...0, 1, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0]), scorer={'score': make_scorer(accuracy_score)}, train=array([ 54,  55,  56,  57,  58,  59,  60,  61,  ..., 152, 153, 154, 155, 156, 157,\n       158, 159]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53]), verbose=0, parameters={'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (3, 3), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (memmap([[[[-0.03378447,  0.19361609],\n          ...888896],\n          [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,... 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), ...}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]])\n        y_train = array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0])\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), y=array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]), **kwargs={})\n    198             self.classes_ = np.unique(y)\n    199             y = np.searchsorted(self.classes_, y)\n    200         else:\n    201             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    202         self.n_classes_ = len(self.classes_)\n--> 203         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]])\n        y = array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0])\n        kwargs = {}\n    204 \n    205     def predict(self, x, **kwargs):\n    206         \"\"\"Returns the class predictions for the given test data.\n    207 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[[-1.6926042 , -0.6605124 ],\n          ...634316],\n          [-0.65906261, -0.60435624]]]]), y=array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,... 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]), **kwargs={})\n    131         elif (not isinstance(self.build_fn, types.FunctionType) and\n    132               not isinstance(self.build_fn, types.MethodType)):\n    133             self.model = self.build_fn(\n    134                 **self.filter_sk_params(self.build_fn.__call__))\n    135         else:\n--> 136             self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n        self.model = undefined\n        self.build_fn = <function build_model>\n        self.filter_sk_params = <bound method BaseWrapper.filter_sk_params of <keras.wrappers.scikit_learn.KerasClassifier object>>\n    137 \n    138         loss_name = self.model.loss\n    139         if hasattr(loss_name, '__name__'):\n    140             loss_name = loss_name.__name__\n\n...........................................................................\n/home/luke/Dropbox/Galvanize/Kaggle/iceburgs_statoil/<ipython-input-12-c7c540e3e6f1> in build_model(shape=(75, 75, 2), window_size=(3, 3), stride=(1, 1), pooling_size=(3, 3), activation_f='relu', op_f='adam', loss_f='sparse_categorical_crossentropy', pad='same', dropout=0.2)\n      2           op_f='adam', loss_f='binary_crossentropy', pad='same', dropout=0.5):\n      3     cnn = Sequential()\n      4     cnn.add(BatchNormalization(input_shape = shape))\n      5     for i in range(5):\n      6         cnn.add(Conv2D(filters=12**i, kernel_size=window_size, strides=stride, padding=pad))\n----> 7         cnn.add(MaxPooling2D(pooling_size))\n      8     cnn.add(GlobalMaxPooling2D())\n      9     cnn.add(Dropout(dropout))\n     10     cnn.add(Dense(8))\n     11     cnn.add(Dense(2, activation = activation_f))\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/models.py in add(self=<keras.models.Sequential object>, layer=<keras.layers.pooling.MaxPooling2D object>)\n    484                           input_masks=[None for _ in self.inputs],\n    485                           output_masks=[None],\n    486                           input_shapes=[x._keras_shape for x in self.inputs],\n    487                           output_shapes=[self.outputs[0]._keras_shape])\n    488         else:\n--> 489             output_tensor = layer(self.outputs[0])\n        output_tensor = undefined\n        layer = <keras.layers.pooling.MaxPooling2D object>\n        self.outputs = [<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>]\n    490             if isinstance(output_tensor, list):\n    491                 raise TypeError('All layers in a Sequential model '\n    492                                 'should have a single output tensor. '\n    493                                 'For multi-output layers, '\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/topology.py in __call__(self=<keras.layers.pooling.MaxPooling2D object>, inputs=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, **kwargs={})\n    598                         kwargs['mask'] = previous_mask\n    599             # Handle automatic shape inference (only useful for Theano).\n    600             input_shape = _collect_input_shape(inputs)\n    601 \n    602             # Actually call the layer, collecting output(s), mask(s), and shape(s).\n--> 603             output = self.call(inputs, **kwargs)\n        output = undefined\n        self.call = <bound method _Pooling2D.call of <keras.layers.pooling.MaxPooling2D object>>\n        inputs = <tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>\n        kwargs = {}\n    604             output_mask = self.compute_mask(inputs, previous_mask)\n    605 \n    606             # If the layer returns tensors from its inputs, unmodified,\n    607             # we copy them to avoid loss of tensor metadata.\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/layers/pooling.py in call(self=<keras.layers.pooling.MaxPooling2D object>, inputs=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>)\n    149     def call(self, inputs):\n    150         output = self._pooling_function(inputs=inputs,\n    151                                         pool_size=self.pool_size,\n    152                                         strides=self.strides,\n    153                                         padding=self.padding,\n--> 154                                         data_format=self.data_format)\n        self.data_format = 'channels_last'\n    155         return output\n    156 \n    157     def get_config(self):\n    158         config = {'pool_size': self.pool_size,\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/layers/pooling.py in _pooling_function(self=<keras.layers.pooling.MaxPooling2D object>, inputs=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, pool_size=(3, 3), strides=(3, 3), padding='valid', data_format='channels_last')\n    212 \n    213     def _pooling_function(self, inputs, pool_size, strides,\n    214                           padding, data_format):\n    215         output = K.pool2d(inputs, pool_size, strides,\n    216                           padding, data_format,\n--> 217                           pool_mode='max')\n    218         return output\n    219 \n    220 \n    221 class AveragePooling2D(_Pooling2D):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in pool2d(x=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, pool_size=(1, 3, 3, 1), strides=(1, 3, 3, 1), padding='VALID', data_format='channels_last', pool_mode='max')\n   3461         pool_size = (1, 1) + pool_size\n   3462 \n   3463     if pool_mode == 'max':\n   3464         x = tf.nn.max_pool(x, pool_size, strides,\n   3465                            padding=padding,\n-> 3466                            data_format=tf_data_format)\n        data_format = 'channels_last'\n        tf_data_format = 'NHWC'\n   3467     elif pool_mode == 'avg':\n   3468         x = tf.nn.avg_pool(x, pool_size, strides,\n   3469                            padding=padding,\n   3470                            data_format=tf_data_format)\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py in max_pool(value=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, ksize=(1, 3, 3, 1), strides=(1, 3, 3, 1), padding='VALID', data_format='NHWC', name='max_pooling2d_4/MaxPool/')\n   1953     return gen_nn_ops._max_pool(value,\n   1954                                 ksize=ksize,\n   1955                                 strides=strides,\n   1956                                 padding=padding,\n   1957                                 data_format=data_format,\n-> 1958                                 name=name)\n        name = 'max_pooling2d_4/MaxPool/'\n   1959 \n   1960 \n   1961 @ops.RegisterStatistics(\"Conv2D\", \"flops\")\n   1962 def _calc_conv_flops(graph, node):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py in _max_pool(input=<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>, ksize=[1, 3, 3, 1], strides=[1, 3, 3, 1], padding=b'VALID', data_format=b'NHWC', name='max_pooling2d_4/MaxPool/')\n   2801   data_format = _execute.make_str(data_format, \"data_format\")\n   2802   _ctx = _context.context()\n   2803   if _ctx.in_graph_mode():\n   2804     _, _, _op = _op_def_lib._apply_op_helper(\n   2805         \"MaxPool\", input=input, ksize=ksize, strides=strides, padding=padding,\n-> 2806         data_format=data_format, name=name)\n        data_format = b'NHWC'\n        name = 'max_pooling2d_4/MaxPool/'\n   2807     _result = _op.outputs[:]\n   2808     _inputs_flat = _op.inputs\n   2809     _attrs = (\"T\", _op.get_attr(\"T\"), \"ksize\", _op.get_attr(\"ksize\"),\n   2810               \"strides\", _op.get_attr(\"strides\"), \"padding\",\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self=<tensorflow.python.framework.op_def_library.OpDefLibrary object>, op_type_name='MaxPool', name='max_pooling2d_4/MaxPool/', **keywords={})\n    782                               if arg.is_ref]\n    783       with _MaybeColocateWith(must_colocate_inputs):\n    784         # Add Op to graph\n    785         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n    786                          input_types=input_types, attrs=attr_protos,\n--> 787                          op_def=op_def)\n        op_def = name: \"MaxPool\"\ninput_arg {\n  name: \"input\"\n  ty...    s: \"NCHW\"\n      s: \"NCHW_VECT_C\"\n    }\n  }\n}\n\n    788       return output_structure, op_def.is_stateful, op\n    789 \n    790 # pylint: enable=invalid-name\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in create_op(self=<tensorflow.python.framework.ops.Graph object>, op_type='MaxPool', inputs=[<tf.Tensor 'conv2d_4/BiasAdd:0' shape=(?, 2, 2, 1728) dtype=float32>], dtypes=[1], input_types=[tf.float32], name='max_pooling2d_4/MaxPool', attrs={'T': type: DT_FLOAT\n, 'data_format': s: \"NHWC\"\n, 'ksize': list {\n  i: 1\n  i: 3\n  i: 3\n  i: 1\n}\n, 'padding': s: \"VALID\"\n, 'strides': list {\n  i: 1\n  i: 3\n  i: 3\n  i: 1\n}\n}, op_def=name: \"MaxPool\"\ninput_arg {\n  name: \"input\"\n  ty...    s: \"NCHW\"\n      s: \"NCHW_VECT_C\"\n    }\n  }\n}\n, compute_shapes=True, compute_device=True)\n   2953         control_inputs=control_inputs,\n   2954         input_types=input_types,\n   2955         original_op=self._default_original_op,\n   2956         op_def=op_def)\n   2957     if compute_shapes:\n-> 2958       set_shapes_for_outputs(ret)\n        ret = <tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>\n   2959     self._add_op(ret)\n   2960     self._record_op_seen_by_control_dependencies(ret)\n   2961 \n   2962     if compute_device:\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in set_shapes_for_outputs(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>)\n   2204     try:\n   2205       shape_func = _default_shape_function_registry.lookup(op.type)\n   2206     except LookupError:\n   2207       shape_func = _call_cpp_shape_fn_and_require_op\n   2208 \n-> 2209   shapes = shape_func(op)\n        shapes = undefined\n        shape_func = <function _set_call_cpp_shape_fn.<locals>.call_with_requiring>\n        op = <tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>\n   2210   if shapes is None:\n   2211     raise RuntimeError(\n   2212         \"Shape function for op %s did not return any shapes\" % op)\n   2213   elif isinstance(shapes, dict):\n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in call_with_requiring(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>)\n   2154     return call_cpp_shape_fn(op, require_shape_fn=False)\n   2155 \n   2156   _call_cpp_shape_fn = call_without_requiring\n   2157 \n   2158   def call_with_requiring(op):\n-> 2159     return call_cpp_shape_fn(op, require_shape_fn=True)\n        op = <tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>\n   2160 \n   2161   _call_cpp_shape_fn_and_require_op = call_with_requiring\n   2162 \n   2163 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py in call_cpp_shape_fn(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>, require_shape_fn=True)\n    622   input_tensors_as_shapes_needed = []\n    623 \n    624   while True:\n    625     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n    626                                   input_tensors_as_shapes_needed,\n--> 627                                   require_shape_fn)\n        require_shape_fn = True\n    628     if not isinstance(res, dict):\n    629       # Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\n    630       return res\n    631 \n\n...........................................................................\n/home/luke/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py in _call_cpp_shape_fn_impl(op=<tf.Operation 'max_pooling2d_4/MaxPool' type=MaxPool>, input_tensors_needed=[], input_tensors_as_shapes_needed=[], require_shape_fn=True)\n    686           input_tensors_as_shapes, status)\n    687   except errors.InvalidArgumentError as err:\n    688     if err.message.startswith(\"No shape inference function exists for op\"):\n    689       missing_shape_fn = True\n    690     else:\n--> 691       raise ValueError(err.message)\n        err.message = undefined\n    692 \n    693   if missing_shape_fn:\n    694     if require_shape_fn:\n    695       raise RuntimeError(\n\nValueError: Negative dimension size caused by subtracting 3 from 2 for 'max_pooling2d_4/MaxPool' (op: 'MaxPool') with input shapes: [?,2,2,1728].\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "use_subset = 1\n",
    "if use_subset:\n",
    "    x_t = images_sub_train\n",
    "    x_v = images_sub_val\n",
    "    y_t = y_sub_train\n",
    "    y_v = y_sub_val\n",
    "else:\n",
    "    x_t = images_train\n",
    "    x_v = images_val\n",
    "    y_t = y_train\n",
    "    y_v = y_val\n",
    "\n",
    "params = {'shape': [x_t.shape[1:]], 'window_size': [(3,3)], 'stride': [(1,1)], 'pooling_size': [(3,3)],\n",
    "          'pad': ['same'], 'activation_f': ['relu', 'sigmoid', 'softmax'], 'op_f': ['adam'],\n",
    "         'epochs': [5, 10], 'validation_data': [(x_v, y_v[:,1])], 'dropout': [0.2, 0.5, 0.7],\n",
    "         'loss_f': ['sparse_categorical_crossentropy']}\n",
    "model = KerasClassifier(build_fn=build_model)\n",
    "\n",
    "grid = GridSearchCV(model, param_grid=params, n_jobs=-1, scoring='accuracy')\n",
    "grid.fit(x_t, y_t[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: \n",
      "0.6875\n",
      "with\n",
      "{'activation_f': 'softmax', 'dropout': 0.2, 'epochs': 10, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.543750 (0.079779) with: {'activation_f': 'relu', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.543750 (0.079779) with: {'activation_f': 'relu', 'dropout': 0.2, 'epochs': 10, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.493750 (0.059352) with: {'activation_f': 'relu', 'dropout': 0.5, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.543750 (0.079779) with: {'activation_f': 'relu', 'dropout': 0.5, 'epochs': 10, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.543750 (0.079779) with: {'activation_f': 'relu', 'dropout': 0.7, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.543750 (0.079779) with: {'activation_f': 'relu', 'dropout': 0.7, 'epochs': 10, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.625000 (0.080195) with: {'activation_f': 'sigmoid', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.650000 (0.076328) with: {'activation_f': 'sigmoid', 'dropout': 0.2, 'epochs': 10, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.643750 (0.018069) with: {'activation_f': 'sigmoid', 'dropout': 0.5, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.543750 (0.079779) with: {'activation_f': 'sigmoid', 'dropout': 0.5, 'epochs': 10, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.543750 (0.041785) with: {'activation_f': 'sigmoid', 'dropout': 0.7, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.587500 (0.131621) with: {'activation_f': 'sigmoid', 'dropout': 0.7, 'epochs': 10, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.637500 (0.109608) with: {'activation_f': 'softmax', 'dropout': 0.2, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.687500 (0.076563) with: {'activation_f': 'softmax', 'dropout': 0.2, 'epochs': 10, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.643750 (0.100330) with: {'activation_f': 'softmax', 'dropout': 0.5, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.612500 (0.073658) with: {'activation_f': 'softmax', 'dropout': 0.5, 'epochs': 10, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.581250 (0.011158) with: {'activation_f': 'softmax', 'dropout': 0.7, 'epochs': 5, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n",
      "0.612500 (0.100667) with: {'activation_f': 'softmax', 'dropout': 0.7, 'epochs': 10, 'loss_f': 'sparse_categorical_crossentropy', 'op_f': 'adam', 'pad': 'same', 'pooling_size': (2, 2), 'shape': (75, 75, 2), 'stride': (1, 1), 'validation_data': (array([[[[-0.03378447,  0.19361609],\n",
      "         [-0.57236388,  0.34365467],\n",
      "         [-0.31516763,  0.61960823],\n",
      "         ...,\n",
      "         [-0.8304801 ,  0.61824206],\n",
      "         [-0.49566242,  1.14775817],\n",
      "         [-0.2823779 ,  1.14773762]],\n",
      "\n",
      "        [[ 0.3269961 , -0.51441877],\n",
      "         [-0.18421965, -0.13592806],\n",
      "         [-0.45725818,  0.55336362],\n",
      "         ...,\n",
      "         [-1.43890859,  0.19221058],\n",
      "         [-0.4581649 ,  0.34224916],\n",
      "         [-0.35049193,  0.55195811]],\n",
      "\n",
      "        [[-0.73935942, -0.22541983],\n",
      "         [-0.45725818,  0.03413296],\n",
      "         [-0.42059822, -0.04950951],\n",
      "         ...,\n",
      "         [-0.57328347,  0.7457625 ],\n",
      "         [-0.83050623,  0.74574224],\n",
      "         [-0.92589114,  0.61818275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.13031286,  0.74695045],\n",
      "         [ 0.32682801,  0.86839492],\n",
      "         [-0.12258285,  0.6839379 ],\n",
      "         ...,\n",
      "         [ 0.37163782,  1.20012441],\n",
      "         [ 0.0764054 , -0.51608178],\n",
      "         [-0.15411951, -0.31983133]],\n",
      "\n",
      "        [[ 0.39495491, -0.13614592],\n",
      "         [ 0.13030018, -0.31840438],\n",
      "         [-0.21617143, -0.95934318],\n",
      "         ...,\n",
      "         [-0.06387922,  1.44791724],\n",
      "         [ 0.02169399,  1.0389818 ],\n",
      "         [ 0.10309   ,  0.86696798]],\n",
      "\n",
      "        [[ 0.18165752,  0.3434374 ],\n",
      "         [-0.18437544, -0.04970769],\n",
      "         [-0.28161335, -1.35246801],\n",
      "         ...,\n",
      "         [ 0.23054868,  0.61800482],\n",
      "         [-0.53417749,  1.49469256],\n",
      "         [-0.24949193,  1.35163016]]],\n",
      "\n",
      "\n",
      "       [[[-0.18332715,  0.152018  ],\n",
      "         [-0.08418438,  0.68684817],\n",
      "         [-0.36292406,  0.31659468],\n",
      "         ...,\n",
      "         [-0.11716486, -0.11757948],\n",
      "         [-0.05299042, -0.02484596],\n",
      "         [-0.5225516 ,  0.06463377]],\n",
      "\n",
      "        [[-0.08417554, -0.31295028],\n",
      "         [-0.02121249,  0.47120359],\n",
      "         [-0.3254348 ,  0.47119126],\n",
      "         ...,\n",
      "         [-0.15020662, -0.63985958],\n",
      "         [-0.25345822, -0.52650876],\n",
      "         [-0.08478162, -0.75852386]],\n",
      "\n",
      "        [[-0.2528606 , -0.41705737],\n",
      "         [ 0.03946919,  0.31659468],\n",
      "         [ 0.12653599,  0.545117  ],\n",
      "         ...,\n",
      "         [-0.32600726,  0.1511175 ],\n",
      "         [-0.40187213,  0.06464698],\n",
      "         [-0.32602397, -0.639886  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.252987  ,  0.06536662],\n",
      "         [-0.40140936, -0.02413807],\n",
      "         ...,\n",
      "         [-0.05309954, -0.21400779],\n",
      "         [ 1.76946387,  0.31551508],\n",
      "         [ 1.35163059,  0.31550157]],\n",
      "\n",
      "        [[ 0.45869289,  0.31642791],\n",
      "         [-0.21785788, -0.21312021],\n",
      "         [ 0.06887585, -0.31315639],\n",
      "         ...,\n",
      "         [ 1.81117991, -1.15181634],\n",
      "         [ 0.038754  , -0.52670195],\n",
      "         [ 0.20857591, -1.01395642]],\n",
      "\n",
      "        [[ 0.57071884,  0.06538012],\n",
      "         [-0.48087111,  0.3948908 ],\n",
      "         [ 0.09789485, -0.75780363],\n",
      "         ...,\n",
      "         [ 0.57012122, -0.31404398],\n",
      "         [ 1.13462933, -1.15182926],\n",
      "         [-0.3636477 , -1.61681075]]],\n",
      "\n",
      "\n",
      "       [[[-0.65789734, -0.64792769],\n",
      "         [-0.57005811, -0.64792769],\n",
      "         [-0.57006656, -1.02181841],\n",
      "         ...,\n",
      "         [ 0.12011716, -0.12651639],\n",
      "         [-0.44698084, -0.76744784],\n",
      "         [-0.61398483, -1.80150413]],\n",
      "\n",
      "        [[-0.18919503,  0.14304939],\n",
      "         [-0.95312476, -0.53457716],\n",
      "         [-0.84881489, -0.42605241],\n",
      "         ...,\n",
      "         [-0.61396773,  0.22580369],\n",
      "         [-0.90071817, -1.02268721],\n",
      "         [-1.1235318 , -1.80150413]],\n",
      "\n",
      "        [[ 0.33285092, -0.03290116],\n",
      "         [-0.12245203,  0.05657828],\n",
      "         [-0.02708882, -0.22192176],\n",
      "         ...,\n",
      "         [-0.57063441, -0.76744784],\n",
      "         [-0.52839893, -1.16058559],\n",
      "         [-1.24719421, -1.62556709]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [-0.40736599, -0.89133574],\n",
      "         [-0.29484519, -0.7669214 ],\n",
      "         ...,\n",
      "         [ 0.14794571, -2.41683396],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.14792804, -0.2231191 ]],\n",
      "\n",
      "        [[-0.40735754, -0.22222417],\n",
      "         [ 0.06291883, -0.64827004],\n",
      "         [-0.09027587, -1.62501481],\n",
      "         ...,\n",
      "         [ 0.03282676, -1.80180654],\n",
      "         [ 0.35677908, -1.6258695 ],\n",
      "         [ 0.22933768, -0.32314207]],\n",
      "\n",
      "        [[-0.25894325, -0.32224774],\n",
      "         [-0.18941864, -0.76690789],\n",
      "         [-0.15571778, -1.02216076],\n",
      "         ...,\n",
      "         [-0.40793384, -0.53577421],\n",
      "         [ 0.00274468, -0.42724917],\n",
      "         [ 0.2556062 , -0.53580005]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.24547504, -0.0769553 ],\n",
      "         [-0.49452922,  0.47445327],\n",
      "         [-0.34612703,  0.61232112],\n",
      "         ...,\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.53455593,  0.251383  ],\n",
      "         [-0.79177677,  0.61115343]],\n",
      "\n",
      "        [[-0.4561586 ,  0.61235635],\n",
      "         [-0.38199958,  0.9275876 ],\n",
      "         [-0.17744236,  0.86756048],\n",
      "         ...,\n",
      "         [ 0.00401062,  0.61117075],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.58176939,  0.67737953]],\n",
      "\n",
      "        [[-0.20983079,  0.74314996],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         [-0.31099791,  0.61232112],\n",
      "         ...,\n",
      "         [ 0.47681733,  1.09841171],\n",
      "         [ 0.62198935, -0.0781588 ],\n",
      "         [ 0.77376962, -0.66933216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.14592529,  0.00906042],\n",
      "         [ 0.00448549, -1.02500056],\n",
      "         [ 0.22007136, -0.077433  ],\n",
      "         ...,\n",
      "         [ 0.19384338, -0.78310342],\n",
      "         [ 0.06028744, -0.45709493],\n",
      "         [ 0.29347697, -0.16809422]],\n",
      "\n",
      "        [[ 0.0610641 , -0.25963685],\n",
      "         [-0.31127607, -0.66857053],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.54030193, -0.26082333],\n",
      "         [ 0.60171666,  0.17244593],\n",
      "         [ 0.4765044 ,  0.472807  ]],\n",
      "\n",
      "        [[-0.24316205,  0.09266531],\n",
      "         [-0.65774577,  0.17361508],\n",
      "         [-0.14594835,  0.17361508],\n",
      "         ...,\n",
      "         [ 0.64145772,  0.61072799],\n",
      "         [ 0.68025153,  0.00785633],\n",
      "         [ 0.43259228, -0.56123725]]],\n",
      "\n",
      "\n",
      "       [[[-0.09093054,  0.2577056 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.12273269, -0.08286361],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.08744615,  0.48537145],\n",
      "         [-0.479653  ,  0.25682183]],\n",
      "\n",
      "        [[-1.04050775, -0.5845126 ],\n",
      "         [-0.40146276, -1.35540881],\n",
      "         [-0.22188468, -0.47598932],\n",
      "         ...,\n",
      "         [ 0.55325965,  0.33531233],\n",
      "         [ 0.44270903, -0.37273664],\n",
      "         [ 0.53171065,  0.00575848]],\n",
      "\n",
      "        [[-0.98579596,  0.09310103],\n",
      "         [-0.18817498, -0.27185867],\n",
      "         [-0.15514244, -0.58454167],\n",
      "         ...,\n",
      "         [ 0.24903619, -0.47684373],\n",
      "         [ 0.29959266,  0.55718466],\n",
      "         [ 0.55324025, -2.46646933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.059097  ,  0.41171143],\n",
      "         [-0.32768755,  0.17611958],\n",
      "         [ 0.39652167,  0.95057521],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.14266431,  0.00516833],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.22334013, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.22333053,  0.69533643],\n",
      "         ...,\n",
      "         [ 0.22277978, -0.58597302],\n",
      "         [ 0.59509844, -0.17707135],\n",
      "         [-0.09191506,  0.17523405]],\n",
      "\n",
      "        [[ 0.67707747, -0.94154629],\n",
      "         [ 0.34884497, -0.58513153],\n",
      "         [ 0.41984894, -0.2724773 ],\n",
      "         ...,\n",
      "         [ 0.89931268, -0.27331908],\n",
      "         [ 0.37228385,  0.17523405],\n",
      "         [ 0.22275096,  0.41079508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09486543, -0.42864939],\n",
      "         [ 0.68999868,  0.53914937],\n",
      "         [ 0.78019978, -0.33242162],\n",
      "         ...,\n",
      "         [-0.10243041,  0.32824689],\n",
      "         [ 0.04025507, -0.52986619],\n",
      "         [ 0.55410239,  0.09967173]],\n",
      "\n",
      "        [[-0.25771612, -0.06370497],\n",
      "         [ 0.09485218, -1.097768  ],\n",
      "         [ 0.31764371,  0.01987761],\n",
      "         ...,\n",
      "         [ 0.06738669, -0.24084816],\n",
      "         [ 0.04024182, -0.240869  ],\n",
      "         [ 0.33987774,  0.53791503]],\n",
      "\n",
      "        [[ 0.0410227 ,  0.01989787],\n",
      "         [ 0.0410227 ,  0.01989787],\n",
      "         [-0.13175389, -0.74135882],\n",
      "         ...,\n",
      "         [ 0.51341717, -0.42984262],\n",
      "         [ 0.12034825,  0.40005012],\n",
      "         [ 0.19677079,  0.73170004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.42915369, -0.24048379],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         [-0.35942822,  1.13407917],\n",
      "         ...,\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.42837146, -0.85670648],\n",
      "         [ 0.03969817,  0.73088851]],\n",
      "\n",
      "        [[ 0.45068386, -0.97414935],\n",
      "         [ 0.68944275, -0.52952237],\n",
      "         [ 0.19700938,  0.73206383],\n",
      "         ...,\n",
      "         [ 0.68867377, -0.43067383],\n",
      "         [ 0.77887487,  0.25344943],\n",
      "         [ 0.70708463, -0.63484471]],\n",
      "\n",
      "        [[ 0.76200023,  0.10003639],\n",
      "         [ 0.70786647,  0.01904816],\n",
      "         [ 0.45064391,  0.01902819],\n",
      "         ...,\n",
      "         [ 0.24531905, -0.63482446],\n",
      "         [ 0.3393341 , -1.66888896],\n",
      "         [ 0.3393341 , -1.66888896]]]]), array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1])), 'window_size': (3, 3)}\n"
     ]
    }
   ],
   "source": [
    "print('Best: ')\n",
    "print(grid.best_score_)\n",
    "print('with')\n",
    "print(grid.best_params_)\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower drop appears to be better\n",
    "acc = []\n",
    "pad = ['valid', 'same']\n",
    "test_var = pad\n",
    "for i in test_var:\n",
    "    acc.append(eval_cnn(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pad, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn.predict(test_images)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions[np.where(predictions > 0.5)]) / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.insert(ids.reshape(-1, 1), [1], predictions.reshape(-1, 1), axis=1)\n",
    "np.savetxt('ice_out.csv', out, delimiter=',', header='id,is_iceberg', fmt=['%s','%1.15f'], comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 10 epochs:\n",
    "val_acc of 0.851 -> 0.423"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psuedo Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psuedo_label(images, angles, y, test_images, test_angles, predictions, tol=0.05):\n",
    "    test_ind_to_add = np.where((predictions >= 1 - tol) | (predictions <= tol))\n",
    "    test_y = [0 if val < 0.5 else 1 for val in predictions[test_ind_to_add]]\n",
    "    test_y = to_categorical(test_y, num_classes=2)\n",
    "    new_images = np.insert(test_images[test_ind_to_add], [0], images, axis=0)\n",
    "    new_angles = np.insert(test_angles[test_ind_to_add], [0], angles, axis=0)\n",
    "    new_y = np.insert(test_y, [0], y, axis=0)\n",
    "    print('Added {} new rows of data'.format(len(test_y)))\n",
    "    return new_images, new_angles, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images, new_angles, new_y = psuedo_label(\n",
    "    images, \n",
    "    angles, \n",
    "    y, \n",
    "    test_images, \n",
    "    test_angles, \n",
    "    predictions, \n",
    "    tol=0.025\n",
    ")\n",
    "new_images_train, new_images_val, new_angles_train, new_angles_val, new_y_train, new_y_val = train_test_split(\n",
    "    new_images, \n",
    "    new_angles, \n",
    "    new_y, \n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = model(\n",
    "    shape=new_images_train.shape[1:], \n",
    "    window_size=(3,3), \n",
    "    stride=(1, 1), \n",
    "    pooling_size=(2,2), \n",
    "    activation_f='softmax',\n",
    "    op_f='adam', \n",
    "    loss_f='binary_crossentropy', \n",
    "    pad='same', \n",
    "    dropout=0.5\n",
    ")\n",
    "cnn2.fit(\n",
    "    new_images_train, \n",
    "    new_y_train, \n",
    "    batch_size=100, \n",
    "    shuffle=True, \n",
    "    validation_data=(new_images_val, new_y_val), \n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = cnn2.predict(test_images)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions2[np.where(predictions2 > 0.5)]) / len(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = np.insert(ids.reshape(-1, 1), [1], predictions2.reshape(-1, 1), axis=1)\n",
    "np.savetxt('ice_out2.csv', out2, delimiter=',', header='id,is_iceberg', fmt=['%s','%1.15f'], comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('stack_minmax_bestbase.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.is_iceberg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x[np.where(x > 0.5)]) / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
